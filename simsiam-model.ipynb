{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "%reset -f"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processing /Users/dhritiman/Documents/projects/mit-main/nobrainer-dev/nobrainer-exp\n",
                        "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
                        "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
                        "  Installing build dependencies ... \u001b[?25ldone\n",
                        "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
                        "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
                        "\u001b[?25hRequirement already satisfied: tensorflow-probability>=0.11.0 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from nobrainer==0.1a1+0.g8e89492.dirty) (0.13.0)\n",
                        "Requirement already satisfied: click in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from nobrainer==0.1a1+0.g8e89492.dirty) (8.0.1)\n",
                        "Requirement already satisfied: tensorflow>=2.4.0 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from nobrainer==0.1a1+0.g8e89492.dirty) (2.5.0)\n",
                        "Requirement already satisfied: numpy in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from nobrainer==0.1a1+0.g8e89492.dirty) (1.19.5)\n",
                        "Requirement already satisfied: scikit-image in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from nobrainer==0.1a1+0.g8e89492.dirty) (0.17.2)\n",
                        "Requirement already satisfied: psutil in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from nobrainer==0.1a1+0.g8e89492.dirty) (5.8.0)\n",
                        "Requirement already satisfied: nibabel in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from nobrainer==0.1a1+0.g8e89492.dirty) (3.2.1)\n",
                        "Requirement already satisfied: absl-py~=0.10 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (0.13.0)\n",
                        "Requirement already satisfied: flatbuffers~=1.12.0 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (1.12)\n",
                        "Requirement already satisfied: google-pasta~=0.2 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (0.2.0)\n",
                        "Requirement already satisfied: h5py~=3.1.0 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (3.1.0)\n",
                        "Requirement already satisfied: gast==0.4.0 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (0.4.0)\n",
                        "Requirement already satisfied: astunparse~=1.6.3 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (1.6.3)\n",
                        "Requirement already satisfied: six~=1.15.0 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (1.15.0)\n",
                        "Requirement already satisfied: typing-extensions~=3.7.4 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (3.7.4.3)\n",
                        "Requirement already satisfied: wheel~=0.35 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (0.36.2)\n",
                        "Requirement already satisfied: keras-nightly~=2.5.0.dev in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (2.5.0.dev2021032900)\n",
                        "Requirement already satisfied: tensorboard~=2.5 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (2.6.0)\n",
                        "Requirement already satisfied: keras-preprocessing~=1.1.2 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (1.1.2)\n",
                        "Requirement already satisfied: protobuf>=3.9.2 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (3.15.8)\n",
                        "Requirement already satisfied: termcolor~=1.1.0 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (1.1.0)\n",
                        "Requirement already satisfied: grpcio~=1.34.0 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (1.34.1)\n",
                        "Requirement already satisfied: opt-einsum~=3.3.0 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (3.3.0)\n",
                        "Requirement already satisfied: wrapt~=1.12.1 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (1.12.1)\n",
                        "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (2.5.0)\n",
                        "Requirement already satisfied: cached-property in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from h5py~=3.1.0->tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (1.5.2)\n",
                        "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (1.6.0.post2)\n",
                        "Requirement already satisfied: werkzeug>=0.11.15 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (2.0.1)\n",
                        "Requirement already satisfied: setuptools>=41.0.0 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (49.6.0.post20210108)\n",
                        "Requirement already satisfied: markdown>=2.6.8 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (3.3.4)\n",
                        "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (0.6.1)\n",
                        "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (0.4.1)\n",
                        "Requirement already satisfied: requests<3,>=2.21.0 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (2.26.0)\n",
                        "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (1.34.0)\n",
                        "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (0.2.7)\n",
                        "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (4.7.2)\n",
                        "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (4.2.2)\n",
                        "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (1.3.0)\n",
                        "Requirement already satisfied: importlib-metadata in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (4.6.3)\n",
                        "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (0.4.8)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (3.1)\n",
                        "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (1.26.6)\n",
                        "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (2.0.0)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (2021.5.30)\n",
                        "Requirement already satisfied: oauthlib>=3.0.0 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (3.1.1)\n",
                        "Requirement already satisfied: decorator in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorflow-probability>=0.11.0->nobrainer==0.1a1+0.g8e89492.dirty) (4.4.2)\n",
                        "Requirement already satisfied: dm-tree in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorflow-probability>=0.11.0->nobrainer==0.1a1+0.g8e89492.dirty) (0.1.6)\n",
                        "Requirement already satisfied: cloudpickle>=1.3 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from tensorflow-probability>=0.11.0->nobrainer==0.1a1+0.g8e89492.dirty) (1.6.0)\n",
                        "Requirement already satisfied: dataclasses in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard~=2.5->tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (0.8)\n",
                        "Requirement already satisfied: zipp>=0.5 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.4.0->nobrainer==0.1a1+0.g8e89492.dirty) (3.5.0)\n",
                        "Requirement already satisfied: packaging>=14.3 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from nibabel->nobrainer==0.1a1+0.g8e89492.dirty) (21.0)\n",
                        "Requirement already satisfied: pyparsing>=2.0.2 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from packaging>=14.3->nibabel->nobrainer==0.1a1+0.g8e89492.dirty) (2.4.7)\n",
                        "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from scikit-image->nobrainer==0.1a1+0.g8e89492.dirty) (3.3.4)\n",
                        "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from scikit-image->nobrainer==0.1a1+0.g8e89492.dirty) (1.1.1)\n",
                        "Requirement already satisfied: networkx>=2.0 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from scikit-image->nobrainer==0.1a1+0.g8e89492.dirty) (2.5.1)\n",
                        "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from scikit-image->nobrainer==0.1a1+0.g8e89492.dirty) (8.3.1)\n",
                        "Requirement already satisfied: tifffile>=2019.7.26 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from scikit-image->nobrainer==0.1a1+0.g8e89492.dirty) (2020.9.3)\n",
                        "Requirement already satisfied: scipy>=1.0.1 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from scikit-image->nobrainer==0.1a1+0.g8e89492.dirty) (1.5.3)\n",
                        "Requirement already satisfied: imageio>=2.3.0 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from scikit-image->nobrainer==0.1a1+0.g8e89492.dirty) (2.9.0)\n",
                        "Requirement already satisfied: cycler>=0.10 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->nobrainer==0.1a1+0.g8e89492.dirty) (0.10.0)\n",
                        "Requirement already satisfied: python-dateutil>=2.1 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->nobrainer==0.1a1+0.g8e89492.dirty) (2.8.2)\n",
                        "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->nobrainer==0.1a1+0.g8e89492.dirty) (1.3.1)\n",
                        "Building wheels for collected packages: nobrainer\n",
                        "  Building wheel for nobrainer (PEP 517) ... \u001b[?25ldone\n",
                        "\u001b[?25h  Created wheel for nobrainer: filename=nobrainer-0.1a1+0.g8e89492.dirty-py3-none-any.whl size=95676 sha256=b4a12314bbb13974212ecdea90834e72fdf218e29b038723a85df2fea00f7eb6\n",
                        "  Stored in directory: /Users/dhritiman/Library/Caches/pip/wheels/1d/3e/e7/ae4b7c6513d2cff5bfeea6eb263919c60b24b717b55157f422\n",
                        "Successfully built nobrainer\n",
                        "Installing collected packages: nobrainer\n",
                        "  Attempting uninstall: nobrainer\n",
                        "    Found existing installation: nobrainer 0.1a1+0.g8e89492.dirty\n",
                        "    Uninstalling nobrainer-0.1a1+0.g8e89492.dirty:\n",
                        "      Successfully uninstalled nobrainer-0.1a1+0.g8e89492.dirty\n",
                        "Successfully installed nobrainer-0.1a1+0.g8e89492.dirty\n"
                    ]
                }
            ],
            "source": [
                "!pip install /Users/dhritiman/Documents/projects/mit-main/nobrainer-dev/nobrainer-exp/"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "in dataset file\n"
                    ]
                }
            ],
            "source": [
                "import nobrainer\n",
                "import tensorflow as tf\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.1a1+0.g8e89492.dirty\n"
                    ]
                }
            ],
            "source": [
                "print(nobrainer.__version__)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "/Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/bin/nobrainer\n"
                    ]
                }
            ],
            "source": [
                "!which nobrainer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Downloading data from https://datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/freesurfer/sub-01/mri/t1.mgz\n",
                        "4276224/4268641 [==============================] - 0s 0us/step\n",
                        "Downloading data from https://datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/freesurfer/sub-01/mri/aparc+aseg.mgz\n",
                        "344064/339508 [==============================] - 0s 0us/step\n",
                        "Downloading data from https://datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/freesurfer/sub-02/mri/t1.mgz\n",
                        "3366912/3360239 [==============================] - 0s 0us/step\n",
                        "Downloading data from https://datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/freesurfer/sub-02/mri/aparc+aseg.mgz\n",
                        "360448/354161 [==============================] - 0s 0us/step\n",
                        "Downloading data from https://datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/freesurfer/sub-03/mri/t1.mgz\n",
                        "3907584/3900552 [==============================] - 0s 0us/step\n",
                        "Downloading data from https://datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/freesurfer/sub-03/mri/aparc+aseg.mgz\n",
                        "352256/350451 [==============================] - 0s 0us/step\n",
                        "Downloading data from https://datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/freesurfer/sub-04/mri/t1.mgz\n",
                        "5120000/5115676 [==============================] - 1s 0us/step\n",
                        "Downloading data from https://datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/freesurfer/sub-04/mri/aparc+aseg.mgz\n",
                        "425984/419833 [==============================] - 0s 0us/step\n",
                        "Downloading data from https://datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/freesurfer/sub-05/mri/t1.mgz\n",
                        "4743168/4738958 [==============================] - 0s 0us/step\n",
                        "Downloading data from https://datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/freesurfer/sub-05/mri/aparc+aseg.mgz\n",
                        "417792/417547 [==============================] - 0s 0us/step\n",
                        "Downloading data from https://datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/freesurfer/sub-06/mri/t1.mgz\n",
                        "4964352/4956283 [==============================] - 0s 0us/step\n",
                        "Downloading data from https://datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/freesurfer/sub-06/mri/aparc+aseg.mgz\n",
                        "409600/403496 [==============================] - 0s 0us/step\n",
                        "Downloading data from https://datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/freesurfer/sub-07/mri/t1.mgz\n",
                        "4276224/4271015 [==============================] - 1s 0us/step\n",
                        "Downloading data from https://datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/freesurfer/sub-07/mri/aparc+aseg.mgz\n",
                        "360448/356833 [==============================] - 0s 0us/step\n",
                        "Downloading data from https://datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/freesurfer/sub-08/mri/t1.mgz\n",
                        "4702208/4702059 [==============================] - 0s 0us/step\n",
                        "Downloading data from https://datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/freesurfer/sub-08/mri/aparc+aseg.mgz\n",
                        "417792/414228 [==============================] - 0s 0us/step\n",
                        "Downloading data from https://datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/freesurfer/sub-09/mri/t1.mgz\n",
                        "4227072/4220278 [==============================] - 0s 0us/step\n",
                        "Downloading data from https://datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/freesurfer/sub-09/mri/aparc+aseg.mgz\n",
                        "401408/395977 [==============================] - 0s 0us/step\n",
                        "Downloading data from https://datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/freesurfer/sub-10/mri/t1.mgz\n",
                        "3874816/3868870 [==============================] - 0s 0us/step\n",
                        "Downloading data from https://datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/freesurfer/sub-10/mri/aparc+aseg.mgz\n",
                        "335872/335557 [==============================] - 0s 0us/step\n"
                    ]
                }
            ],
            "source": [
                "import random\n",
                "\n",
                "csv_of_filepaths = nobrainer.utils.get_data()\n",
                "filepaths = nobrainer.io.read_csv(csv_of_filepaths)\n",
                "\n",
                "# Add random boolean values\n",
                "filepaths = [(x, random.choice([0, 1])) for x, _ in filepaths]\n",
                "\n",
                "train_paths = filepaths[:9]\n",
                "evaluate_paths = filepaths[9:]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[('/var/folders/sh/dz5rd4yx2gs2cw1rgr6lxrvw0000gn/T/nobrainer-data/datasets/sub-01_t1.mgz',\n",
                            "  0),\n",
                            " ('/var/folders/sh/dz5rd4yx2gs2cw1rgr6lxrvw0000gn/T/nobrainer-data/datasets/sub-02_t1.mgz',\n",
                            "  1),\n",
                            " ('/var/folders/sh/dz5rd4yx2gs2cw1rgr6lxrvw0000gn/T/nobrainer-data/datasets/sub-03_t1.mgz',\n",
                            "  0),\n",
                            " ('/var/folders/sh/dz5rd4yx2gs2cw1rgr6lxrvw0000gn/T/nobrainer-data/datasets/sub-04_t1.mgz',\n",
                            "  1),\n",
                            " ('/var/folders/sh/dz5rd4yx2gs2cw1rgr6lxrvw0000gn/T/nobrainer-data/datasets/sub-05_t1.mgz',\n",
                            "  0),\n",
                            " ('/var/folders/sh/dz5rd4yx2gs2cw1rgr6lxrvw0000gn/T/nobrainer-data/datasets/sub-06_t1.mgz',\n",
                            "  1),\n",
                            " ('/var/folders/sh/dz5rd4yx2gs2cw1rgr6lxrvw0000gn/T/nobrainer-data/datasets/sub-07_t1.mgz',\n",
                            "  1),\n",
                            " ('/var/folders/sh/dz5rd4yx2gs2cw1rgr6lxrvw0000gn/T/nobrainer-data/datasets/sub-08_t1.mgz',\n",
                            "  1),\n",
                            " ('/var/folders/sh/dz5rd4yx2gs2cw1rgr6lxrvw0000gn/T/nobrainer-data/datasets/sub-09_t1.mgz',\n",
                            "  0),\n",
                            " ('/var/folders/sh/dz5rd4yx2gs2cw1rgr6lxrvw0000gn/T/nobrainer-data/datasets/sub-10_t1.mgz',\n",
                            "  0)]"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "filepaths"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Verifying 9 examples\n",
                        "9/9 [==============================] - 0s 2ms/step\n",
                        "Verifying 1 examples\n",
                        "1/1 [==============================] - 0s 111ms/step\n"
                    ]
                }
            ],
            "source": [
                "# Verify that all volumes have the same shape and that labels are integer-ish.\n",
                "\n",
                "invalid = nobrainer.io.verify_features_labels(train_paths)\n",
                "assert not invalid\n",
                "\n",
                "invalid = nobrainer.io.verify_features_labels(evaluate_paths)\n",
                "assert not invalid"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "!mkdir -p data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "3/3 [==============================] - 9s 615ms/step\n",
                        "1/1 [==============================] - 3s 3s/step\n"
                    ]
                }
            ],
            "source": [
                "# Convert training and evaluation data to TFRecords.\n",
                "\n",
                "nobrainer.tfrecord.write(\n",
                "    features_labels=train_paths,\n",
                "    filename_template='data/data-train_shard-{shard:03d}.tfrec',\n",
                "    examples_per_shard=3)\n",
                "\n",
                "nobrainer.tfrecord.write(\n",
                "    features_labels=evaluate_paths,\n",
                "    filename_template='data/data-evaluate_shard-{shard:03d}.tfrec',\n",
                "    examples_per_shard=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "data-evaluate_shard-000.tfrec data-train_shard-001.tfrec\n",
                        "data-train_shard-000.tfrec    data-train_shard-002.tfrec\n"
                    ]
                }
            ],
            "source": [
                "!ls data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "n_classes = 1\n",
                "batch_size = 1\n",
                "volume_shape = (256, 256, 256)\n",
                "block_shape = (8, 8, 8)\n",
                "n_epochs = None\n",
                "num_parallel_calls = 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "after get dataset\n",
                        "before calling augment\n",
                        "scalar true\n",
                        "augment type: true, add Gaussian Noise\n",
                        "after get dataset\n",
                        "before calling augment\n",
                        "scalar true\n",
                        "augment type: false, add random transform\n",
                        "WARNING:tensorflow:From /Users/dhritiman/opt/anaconda3/envs/nobrainer-dev/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
                        "Instructions for updating:\n",
                        "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
                        "after get dataset\n",
                        "before calling augment\n"
                    ]
                }
            ],
            "source": [
                "dataset_train_1 = nobrainer.dataset.get_dataset(\n",
                "    file_pattern=\"data/data-train_shard*.tfrec\",\n",
                "    n_classes=n_classes,\n",
                "    batch_size=batch_size,\n",
                "    volume_shape=volume_shape,\n",
                "    scalar_label=True,\n",
                "    augment=True,\n",
                "    augmentType=True,\n",
                "    block_shape=block_shape,\n",
                "    n_epochs=n_epochs,\n",
                "    num_parallel_calls=num_parallel_calls,\n",
                ")\n",
                "\n",
                "dataset_train_2 = nobrainer.dataset.get_dataset(\n",
                "    file_pattern=\"data/data-train_shard*.tfrec\",\n",
                "    n_classes=n_classes,\n",
                "    batch_size=batch_size,\n",
                "    volume_shape=volume_shape,\n",
                "    scalar_label=True,\n",
                "    augment=True,\n",
                "    augmentType=False,\n",
                "    block_shape=block_shape,\n",
                "    n_epochs=n_epochs,\n",
                "    num_parallel_calls=num_parallel_calls,\n",
                ")\n",
                "\n",
                "dataset_evaluate = nobrainer.dataset.get_dataset(\n",
                "    file_pattern=\"data/data-evaluate_shard-*.tfrec\",\n",
                "    n_classes=n_classes,\n",
                "    batch_size=batch_size,\n",
                "    volume_shape=volume_shape,\n",
                "    scalar_label=True,\n",
                "    augment=False,\n",
                "    block_shape=block_shape,\n",
                "    n_epochs=1,\n",
                "    num_parallel_calls=num_parallel_calls,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<RepeatDataset shapes: ((1, 8, 8, 8, 1), (1,)), types: (tf.float32, tf.float32)>"
                        ]
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dataset_train_1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<RepeatDataset shapes: ((1, 8, 8, 8, 1), (1,)), types: (tf.float32, tf.float32)>"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dataset_train_2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<RepeatDataset shapes: ((1, 8, 8, 8, 1), (1,)), types: (tf.float32, tf.float32)>"
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dataset_evaluate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<MapDataset shapes: (1, 8, 8, 8, 1), types: tf.float32>"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dataset_train_1 = dataset_train_1.map(lambda x, y:x)\n",
                "\n",
                "dataset_train_1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<MapDataset shapes: (1, 8, 8, 8, 1), types: tf.float32>"
                        ]
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dataset_train_2 = dataset_train_2.map(lambda x, y:x)\n",
                "dataset_train_2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "from nobrainer.models.brainsiam import brainsiam\n",
                "from nobrainer import training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "projection_dim = 2048\n",
                "latent_dim = 512\n",
                "weight_decay = 0.0005"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "projection dimension is:  2048\n",
                        "latent dimension:  512\n",
                        "Model: \"encoder\"\n",
                        "_________________________________________________________________\n",
                        "Layer (type)                 Output Shape              Param #   \n",
                        "=================================================================\n",
                        "input_2 (InputLayer)         [(None, 8, 8, 8, 1)]      0         \n",
                        "_________________________________________________________________\n",
                        "highresnet (Functional)      (None, 8, 8, 8, 1)        874785    \n",
                        "_________________________________________________________________\n",
                        "backbone_pool (GlobalAverage (None, 1)                 0         \n",
                        "_________________________________________________________________\n",
                        "dense (Dense)                (None, 2048)              2048      \n",
                        "_________________________________________________________________\n",
                        "batch_normalization_18 (Batc (None, 2048)              8192      \n",
                        "_________________________________________________________________\n",
                        "leaky_re_lu (LeakyReLU)      (None, 2048)              0         \n",
                        "_________________________________________________________________\n",
                        "dense_1 (Dense)              (None, 2048)              4194304   \n",
                        "_________________________________________________________________\n",
                        "batch_normalization_19 (Batc (None, 2048)              8192      \n",
                        "=================================================================\n",
                        "Total params: 5,087,521\n",
                        "Trainable params: 5,077,985\n",
                        "Non-trainable params: 9,536\n",
                        "_________________________________________________________________\n",
                        "Model: \"predictor\"\n",
                        "_________________________________________________________________\n",
                        "Layer (type)                 Output Shape              Param #   \n",
                        "=================================================================\n",
                        "dense_2 (Dense)              (None, 512)               1048576   \n",
                        "_________________________________________________________________\n",
                        "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
                        "_________________________________________________________________\n",
                        "batch_normalization_20 (Batc (None, 512)               2048      \n",
                        "_________________________________________________________________\n",
                        "dense_3 (Dense)              (None, 2048)              1050624   \n",
                        "=================================================================\n",
                        "Total params: 2,101,248\n",
                        "Trainable params: 2,100,224\n",
                        "Non-trainable params: 1,024\n",
                        "_________________________________________________________________\n"
                    ]
                }
            ],
            "source": [
                "#/Users/dhritiman/Documents/projects/mit-main/nobrainer-dev/nobrainer/models/wip_simsiam_brain.py\n",
                "\n",
                "encoder, predictor = brainsiam(n_classes=n_classes, input_shape=(*block_shape, 1),weight_decay = weight_decay,\n",
                "    projection_dim = projection_dim,\n",
                "    latent_dim = latent_dim,\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model: \"encoder\"\n",
                        "_________________________________________________________________\n",
                        "Layer (type)                 Output Shape              Param #   \n",
                        "=================================================================\n",
                        "input_2 (InputLayer)         [(None, 8, 8, 8, 1)]      0         \n",
                        "_________________________________________________________________\n",
                        "highresnet (Functional)      (None, 8, 8, 8, 1)        874785    \n",
                        "_________________________________________________________________\n",
                        "backbone_pool (GlobalAverage (None, 1)                 0         \n",
                        "_________________________________________________________________\n",
                        "dense (Dense)                (None, 2048)              2048      \n",
                        "_________________________________________________________________\n",
                        "batch_normalization_18 (Batc (None, 2048)              8192      \n",
                        "_________________________________________________________________\n",
                        "leaky_re_lu (LeakyReLU)      (None, 2048)              0         \n",
                        "_________________________________________________________________\n",
                        "dense_1 (Dense)              (None, 2048)              4194304   \n",
                        "_________________________________________________________________\n",
                        "batch_normalization_19 (Batc (None, 2048)              8192      \n",
                        "=================================================================\n",
                        "Total params: 5,087,521\n",
                        "Trainable params: 5,077,985\n",
                        "Non-trainable params: 9,536\n",
                        "_________________________________________________________________\n"
                    ]
                }
            ],
            "source": [
                "encoder.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<ZipDataset shapes: ((1, 8, 8, 8, 1), (1, 8, 8, 8, 1)), types: (tf.float32, tf.float32)>\n"
                    ]
                }
            ],
            "source": [
                "augment_noise_rigid = tf.data.Dataset.zip((dataset_train_1, dataset_train_2))\n",
                "print(augment_noise_rigid)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "128"
                        ]
                    },
                    "execution_count": 25,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "steps = nobrainer.dataset.get_steps_per_epoch(\n",
                "    n_volumes = len(train_paths),\n",
                "    volume_shape=volume_shape,\n",
                "    block_shape=block_shape,\n",
                "    batch_size=batch_size\n",
                ")\n",
                "\n",
                "steps = 128\n",
                "\n",
                "steps"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": [
                "lr_decayed_fn = tf.keras.experimental.CosineDecay(\n",
                "    initial_learning_rate=0.01, decay_steps=steps #original initial rate = 0.001\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": [
                "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
                "    monitor=\"loss\", patience=5, restore_best_weights=True\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [],
            "source": [
                "checkpoint_path = \"/gdrive/MyDrive/training_noise_rigid/cp-{epoch:04d}.ckpt\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": [
                "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, verbose=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [],
            "source": [
                "EPOCHS = 5\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = training.BrainSiamese(encoder, predictor)  #SimSiam(encoder, predictor)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.compile(optimizer=tf.keras.optimizers.SGD(lr_decayed_fn, momentum=0.6))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/5\n",
                        "128/128 [==============================] - 18s 86ms/step - loss: -0.9756\n",
                        "Epoch 2/5\n",
                        "128/128 [==============================] - 11s 83ms/step - loss: -1.0000\n",
                        "Epoch 3/5\n",
                        "128/128 [==============================] - 11s 85ms/step - loss: -1.0000\n",
                        "Epoch 4/5\n",
                        "128/128 [==============================] - 11s 83ms/step - loss: -1.0000\n",
                        "Epoch 5/5\n",
                        "128/128 [==============================] - 10s 81ms/step - loss: -1.0000\n"
                    ]
                }
            ],
            "source": [
                "history = model.fit(augment_noise_rigid, epochs=EPOCHS, steps_per_epoch = steps, callbacks=[early_stopping])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 126,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tuple"
                        ]
                    },
                    "execution_count": 126,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "input_1 = (1, 8, 8, 8, 1)\n",
                "input_1.__class__"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 97,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(1, 8, 8, 8, 1)\n",
                        "<class 'numpy.ndarray'>\n"
                    ]
                }
            ],
            "source": [
                "x = 10 * np.random.random(input_1)\n",
                "print(x.shape)\n",
                "print(x.__class__)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 67,
            "metadata": {},
            "outputs": [],
            "source": [
                "y = input_1[1:]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 93,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(8, 8, 8, 1)\n",
                        "<class 'tuple'>\n"
                    ]
                }
            ],
            "source": [
                "a = (*block_shape, 1)\n",
                "print(a)\n",
                "print(a.__class__)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(10, 256)\n"
                    ]
                }
            ],
            "source": [
                "print((np.random.random((10, 256)).shape))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 108,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "TensorShape([0, 2048])"
                        ]
                    },
                    "execution_count": 108,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                " y1 = encoder(x[1:])\n",
                " y1.shape\n",
                " #n_classes=n_classes)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 111,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "2048\n"
                    ]
                }
            ],
            "source": [
                "sh = y1.get_shape().as_list()\n",
                "print(sh[1])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 112,
            "metadata": {},
            "outputs": [],
            "source": [
                "assert sh[1] == projection_dim"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install pytest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pytest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 113,
            "metadata": {},
            "outputs": [],
            "source": [
                "input_shape=(1, 32, 32, 32, 1)\n",
                "x = 10 * np.random.random(input_shape)\n",
                "\n",
                "n_classes=1\n",
                "weight_decay = 0.0005\n",
                "projection_dim = 2048\n",
                "latent_dim = 512\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 114,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "projection dimension is:  2048\n",
                        "latent dimension:  512\n",
                        "Model: \"encoder\"\n",
                        "_________________________________________________________________\n",
                        "Layer (type)                 Output Shape              Param #   \n",
                        "=================================================================\n",
                        "input_11 (InputLayer)        [(None, 32, 32, 32, 1)]   0         \n",
                        "_________________________________________________________________\n",
                        "highresnet (Functional)      (None, 32, 32, 32, 1)     874785    \n",
                        "_________________________________________________________________\n",
                        "backbone_pool (GlobalAverage (None, 1)                 0         \n",
                        "_________________________________________________________________\n",
                        "dense_12 (Dense)             (None, 2048)              2048      \n",
                        "_________________________________________________________________\n",
                        "batch_normalization_81 (Batc (None, 2048)              8192      \n",
                        "_________________________________________________________________\n",
                        "leaky_re_lu_6 (LeakyReLU)    (None, 2048)              0         \n",
                        "_________________________________________________________________\n",
                        "dense_13 (Dense)             (None, 2048)              4194304   \n",
                        "_________________________________________________________________\n",
                        "batch_normalization_82 (Batc (None, 2048)              8192      \n",
                        "=================================================================\n",
                        "Total params: 5,087,521\n",
                        "Trainable params: 5,077,985\n",
                        "Non-trainable params: 9,536\n",
                        "_________________________________________________________________\n",
                        "Model: \"predictor\"\n",
                        "_________________________________________________________________\n",
                        "Layer (type)                 Output Shape              Param #   \n",
                        "=================================================================\n",
                        "dense_14 (Dense)             (None, 512)               1048576   \n",
                        "_________________________________________________________________\n",
                        "leaky_re_lu_7 (LeakyReLU)    (None, 512)               0         \n",
                        "_________________________________________________________________\n",
                        "batch_normalization_83 (Batc (None, 512)               2048      \n",
                        "_________________________________________________________________\n",
                        "dense_15 (Dense)             (None, 2048)              1050624   \n",
                        "=================================================================\n",
                        "Total params: 2,101,248\n",
                        "Trainable params: 2,100,224\n",
                        "Non-trainable params: 1,024\n",
                        "_________________________________________________________________\n"
                    ]
                }
            ],
            "source": [
                "encoder, predictor = brainsiam(\n",
                "      n_classes,\n",
                "      input_shape=input_shape[1:],\n",
                "      weight_decay=weight_decay,\n",
                "      projection_dim=projection_dim,\n",
                "      latent_dim=latent_dim,\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 121,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model: \"predictor\"\n",
                        "_________________________________________________________________\n",
                        "Layer (type)                 Output Shape              Param #   \n",
                        "=================================================================\n",
                        "dense_14 (Dense)             (None, 512)               1048576   \n",
                        "_________________________________________________________________\n",
                        "leaky_re_lu_7 (LeakyReLU)    (None, 512)               0         \n",
                        "_________________________________________________________________\n",
                        "batch_normalization_83 (Batc (None, 512)               2048      \n",
                        "_________________________________________________________________\n",
                        "dense_15 (Dense)             (None, 2048)              1050624   \n",
                        "=================================================================\n",
                        "Total params: 2,101,248\n",
                        "Trainable params: 2,100,224\n",
                        "Non-trainable params: 1,024\n",
                        "_________________________________________________________________\n"
                    ]
                }
            ],
            "source": [
                "predictor.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 115,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[0, 2048]"
                        ]
                    },
                    "execution_count": 115,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "encoder_output = encoder(x[1:])\n",
                "enc_output_shape = encoder_output.get_shape().as_list()\n",
                "enc_output_shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 132,
            "metadata": {},
            "outputs": [],
            "source": [
                "projection_dim = 2048"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 120,
            "metadata": {},
            "outputs": [],
            "source": [
                "assert enc_output_shape[1] == projection_dim, 'encoder output shape not the same as projection dim'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 123,
            "metadata": {},
            "outputs": [],
            "source": [
                "predictor_out = predictor(encoder_output)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 125,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[0, 2048]"
                        ]
                    },
                    "execution_count": 125,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "pred_output_shape = predictor_out.get_shape().as_list()\n",
                "pred_output_shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 133,
            "metadata": {},
            "outputs": [],
            "source": [
                "assert pred_output_shape[1] == projection_dim, 'predictor output shape not the same as projection dim'"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "85ad1268aed0ebf4f79dd6e8cbf45ce3965d38d067946b247c788146448eb601"
        },
        "kernelspec": {
            "display_name": "Python 3.6.13 64-bit ('nobrainer-dev': conda)",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.13"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
